# Recent adversarial/offensive AI security research (last ~6 months)

- **Generated**: 2025-12-24 (UTC)
- **Cutoff (inclusive)**: 2025-06-24
- **Count**: 111

This bibliography is **auto-generated from arXiv API queries** across security-relevant keywords (prompt injection, jailbreaks, red teaming, agentic cyber, extraction/inversion, poisoning/backdoors, etc.).
It is intended to ground documentation and *interpretation* of NeurInSpectre outputs; it does not imply NeurInSpectre implements each work.

## Sources

1. [ChatGPT: Excellent Paper! Accept It. Editor: Imposter Found! Review Rejected](http://arxiv.org/abs/2512.20405v1) — arXiv:2512.20405 — 2025-12-23 — cs.CR — Kanchon Gharami, Sanjiv Kumar Sarkar, Yongxin Liu, Shafika Showkat Moni
2. [AprielGuard](http://arxiv.org/abs/2512.20293v1) — arXiv:2512.20293 — 2025-12-23 — cs.CL — Jaykumar Kasundra, Anjaneya Praharaj, Sourabh Surana, Lakshmi Sirisha Chodisetty, Sourav Sharma, et al.
3. [Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline](http://arxiv.org/abs/2512.19011v1) — arXiv:2512.19011 — 2025-12-22 — cs.CR — Akshaj Prashanth Rao, Advait Singh, Saumya Kumaar Saksena, Dhruv Kumar
4. [Beyond the Benchmark: Innovative Defenses Against Prompt Injection Attacks](http://arxiv.org/abs/2512.16307v1) — arXiv:2512.16307 — 2025-12-18 — cs.CR — Safwan Shaheer, G. M. Refatul Islam, Mohammad Rafid Hamid, Tahsin Zaman Jilan
5. [MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval](http://arxiv.org/abs/2512.16962v1) — arXiv:2512.16962 — 2025-12-18 — cs.CR — Saksham Sahai Srivastava, Haoyu He
6. [Quantifying Return on Security Controls in LLM Systems](http://arxiv.org/abs/2512.15081v1) — arXiv:2512.15081 — 2025-12-17 — cs.CR — Richard Helder Moulton, Austin O'Brien, John D. Hastings
7. [Penetration Testing of Agentic AI: A Comparative Security Analysis Across Models and Frameworks](http://arxiv.org/abs/2512.14860v1) — arXiv:2512.14860 — 2025-12-16 — cs.CR — Viet K. Nguyen, Mohammad I. Husain
8. [Cisco Integrated AI Security and Safety Framework Report](http://arxiv.org/abs/2512.12921v1) — arXiv:2512.12921 — 2025-12-15 — cs.CR — Amy Chang, Tiffany Saade, Sanket Mendapara, Adam Swanda, Ankit Garg
9. [ceLLMate: Sandboxing Browser AI Agents](http://arxiv.org/abs/2512.12594v1) — arXiv:2512.12594 — 2025-12-14 — cs.CR — Luoxi Meng, Henry Feng, Ilia Shumailov, Earlence Fernandes
10. [Detecting Prompt Injection Attacks Against Application Using Classifiers](http://arxiv.org/abs/2512.12583v1) — arXiv:2512.12583 — 2025-12-14 — cs.CR — Safwan Shaheer, G. M. Refatul Islam, Mohammad Rafid Hamid, Md. Abrar Faiaz Khan, Md. Omar Faruk, et al.
11. [When Reject Turns into Accept: Quantifying the Vulnerability of LLM-Based Scientific Reviewers to Indirect Prompt Injection](http://arxiv.org/abs/2512.10449v2) — arXiv:2512.10449 — 2025-12-11 — cs.AI — Devanshu Sahoo, Manish Prasad, Vasudev Majhi, Jahnvi Singh, Vinay Chamola, et al.
12. [Phishing Email Detection Using Large Language Models](http://arxiv.org/abs/2512.10104v2) — arXiv:2512.10104 — 2025-12-10 — cs.CR — Najmul Hasan, Prashanth BusiReddyGari, Haitao Zhao, Yihao Ren, Jinsheng Xu, et al.
13. [ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data](http://arxiv.org/abs/2512.09321v3) — arXiv:2512.09321 — 2025-12-10 — cs.CR — Reachal Wang, Yuqi Jia, Neil Zhenqiang Gong
14. [Insured Agents: A Decentralized Trust Insurance Mechanism for Agentic Economy](http://arxiv.org/abs/2512.08737v1) — arXiv:2512.08737 — 2025-12-09 — cs.CY — Botao 'Amber' Hu, Bangdao Chen
15. [Attention is All You Need to Defend Against Indirect Prompt Injection Attacks in LLMs](http://arxiv.org/abs/2512.08417v2) — arXiv:2512.08417 — 2025-12-09 — cs.CR — Yinan Zhong, Qianhao Miao, Yanjiao Chen, Jiangyi Deng, Yushi Cheng, et al.
16. [Systematization of Knowledge: Security and Safety in the Model Context Protocol Ecosystem](http://arxiv.org/abs/2512.08290v2) — arXiv:2512.08290 — 2025-12-09 — cs.CR — Shiva Gaire, Srijan Gyawali, Saroj Mishra, Suman Niroula, Dilip Thakur, et al.
17. [Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents](http://arxiv.org/abs/2512.06716v1) — arXiv:2512.06716 — 2025-12-07 — cs.AI — Zhibo Liang, Tianze Hu, Zaiye Chen, Mingjie Tang
18. [Securing the Model Context Protocol: Defending LLMs Against Tool Poisoning and Adversarial Attacks](http://arxiv.org/abs/2512.06556v1) — arXiv:2512.06556 — 2025-12-06 — cs.CR — Saeid Jamshidi, Kawser Wazed Nafi, Arghavan Moradi Dakhel, Negar Shahabi, Foutse Khomh, et al.
19. [ARGUS: Defending Against Multimodal Indirect Prompt Injection via Steering Instruction-Following Behavior](http://arxiv.org/abs/2512.05745v1) — arXiv:2512.05745 — 2025-12-05 — cs.CR — Weikai Lu, Ziqian Zeng, Kehua Zhang, Haoran Li, Huiping Zhuang, et al.
20. [Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems](http://arxiv.org/abs/2512.04895v1) — arXiv:2512.04895 — 2025-12-04 — cs.AI — M Zeeshan, Saud Satti
21. [ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications](http://arxiv.org/abs/2512.04785v1) — arXiv:2512.04785 — 2025-12-04 — cs.AI — Eranga Bandara, Amin Hass, Ross Gore, Sachin Shetty, Ravi Mukkamala, et al.
22. [Boundary-Aware Test-Time Adaptation for Zero-Shot Medical Image Segmentation](http://arxiv.org/abs/2512.04520v1) — arXiv:2512.04520 — 2025-12-04 — cs.CV — Chenlin Xu, Lei Zhang, Lituan Wang, Xinyu Pu, Pengfei Ma, et al.
23. [Securing Large Language Models (LLMs) from Prompt Injection Attacks](http://arxiv.org/abs/2512.01326v1) — arXiv:2512.01326 — 2025-12-01 — cs.CR — Omar Farooq Khan Suri, John McCrae
24. [Mitigating Indirect Prompt Injection via Instruction-Following Intent Analysis](http://arxiv.org/abs/2512.00966v1) — arXiv:2512.00966 — 2025-11-30 — cs.CR — Mintong Kang, Chong Xiang, Sanjay Kariyappa, Chaowei Xiao, Bo Li, et al.
25. [On the Regulatory Potential of User Interfaces for AI Agent Governance](http://arxiv.org/abs/2512.00742v1) — arXiv:2512.00742 — 2025-11-30 — cs.CY — K. J. Kevin Feng, Tae Soo Kim, Rock Yuren Pang, Faria Huq, Tal August, et al.
26. [Are LLMs Good Safety Agents or a Propaganda Engine?](http://arxiv.org/abs/2511.23174v1) — arXiv:2511.23174 — 2025-11-28 — cs.CL — Neemesh Yadav, Francesco Ortu, Jiarui Liu, Joeun Yook, Bernhard Schölkopf, et al.
27. [BrowseSafe: Understanding and Preventing Prompt Injection Within AI Browser Agents](http://arxiv.org/abs/2511.20597v1) — arXiv:2511.20597 — 2025-11-25 — cs.LG — Kaiyuan Zhang, Mark Tenenholtz, Kyle Polley, Jerry Ma, Denis Yarats, et al.
28. [Prompt Fencing: A Cryptographic Approach to Establishing Security Boundaries in Large Language Model Prompts](http://arxiv.org/abs/2511.19727v1) — arXiv:2511.19727 — 2025-11-24 — cs.CR — Steven Peh
29. [Semantics as a Shield: Label Disguise Defense (LDD) against Prompt Injection in LLM Sentiment Classification](http://arxiv.org/abs/2511.21752v1) — arXiv:2511.21752 — 2025-11-23 — cs.CL — Yanxi Li, Ruocheng Shan
30. [Z-Space: A Multi-Agent Tool Orchestration Framework for Enterprise-Grade LLM Automation](http://arxiv.org/abs/2511.19483v1) — arXiv:2511.19483 — 2025-11-23 — cs.SE — Qingsong He, Jing Nan, Jiayu Jiao, Liangjie Tang, Xiaodong Xu, et al.
31. [Building Browser Agents: Architecture, Security, and Practical Solutions](http://arxiv.org/abs/2511.19477v1) — arXiv:2511.19477 — 2025-11-22 — cs.SE — Aram Vardanyan
32. [The Shawshank Redemption of Embodied AI: Understanding and Benchmarking Indirect Environmental Jailbreaks](http://arxiv.org/abs/2511.16347v1) — arXiv:2511.16347 — 2025-11-20 — cs.CR — Chunyang Li, Zifeng Kang, Junwei Zhang, Zhuo Ma, Anda Cheng, et al.
33. [Securing AI Agents Against Prompt Injection Attacks](http://arxiv.org/abs/2511.15759v1) — arXiv:2511.15759 — 2025-11-19 — cs.CR — Badrinath Ramakrishnan, Akshaya Balaji
34. [Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks](http://arxiv.org/abs/2511.15203v1) — arXiv:2511.15203 — 2025-11-19 — cs.CR — Zimo Ji, Xunguang Wang, Zongjie Li, Pingchuan Ma, Yudong Gao, et al.
35. [GRAPHTEXTACK: A Realistic Black-Box Node Injection Attack on LLM-Enhanced GNNs](http://arxiv.org/abs/2511.12423v1) — arXiv:2511.12423 — 2025-11-16 — cs.CR — Jiaji Ma, Puja Trivedi, Danai Koutra
36. [Privacy-Preserving Prompt Injection Detection for LLMs Using Federated Learning and Embedding-Based NLP Classification](http://arxiv.org/abs/2511.12295v1) — arXiv:2511.12295 — 2025-11-15 — cs.CR — Hasini Jayathilaka
37. [PISanitizer: Preventing Prompt Injection to Long-Context LLMs via Prompt Sanitization](http://arxiv.org/abs/2511.10720v1) — arXiv:2511.10720 — 2025-11-13 — cs.CR — Runpeng Geng, Yanting Wang, Chenlong Yin, Minhao Cheng, Ying Chen, et al.
38. [RAG-targeted Adversarial Attack on LLM-based Threat Detection and Mitigation Framework](http://arxiv.org/abs/2511.06212v1) — arXiv:2511.06212 — 2025-11-09 — cs.CR — Seif Ikbarieh, Kshitiz Aryal, Maanak Gupta
39. [Injecting Falsehoods: Adversarial Man-in-the-Middle Attacks Undermining Factual Recall in LLMs](http://arxiv.org/abs/2511.05919v2) — arXiv:2511.05919 — 2025-11-08 — cs.CR — Alina Fastowski, Bardh Prenkaj, Yuxiao Li, Gjergji Kasneci
40. [MCP-RiskCue: Can LLM Infer Risk Information From MCP Server System Logs?](http://arxiv.org/abs/2511.05867v2) — arXiv:2511.05867 — 2025-11-08 — cs.CR — Jiayi Fu, Qiyao Sun
41. [When AI Meets the Web: Prompt Injection Risks in Third-Party AI Chatbot Plugins](http://arxiv.org/abs/2511.05797v1) — arXiv:2511.05797 — 2025-11-08 — cs.CR — Yigitcan Kaya, Anton Landerer, Stijn Pletinckx, Michelle Zimmermann, Christopher Kruegel, et al.
42. [Large Language Models for Cyber Security](http://arxiv.org/abs/2511.04508v1) — arXiv:2511.04508 — 2025-11-06 — cs.CR — Raunak Somani, Aswani Kumar Cherukuri
43. [Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof, Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2, ERC-8004, and Beyond](http://arxiv.org/abs/2511.03434v1) — arXiv:2511.03434 — 2025-11-05 — cs.HC — Botao 'Amber' Hu, Helena Rong
44. [Death by a Thousand Prompts: Open Model Vulnerability Analysis](http://arxiv.org/abs/2511.03247v1) — arXiv:2511.03247 — 2025-11-05 — cs.CR — Amy Chang, Nicholas Conley, Harish Santhanalakshmi Ganesan, Adam Swanda
45. [Prompt Injection as an Emerging Threat: Evaluating the Resilience of Large Language Models](http://arxiv.org/abs/2511.01634v2) — arXiv:2511.01634 — 2025-11-03 — cs.CR — Daniyal Ganiuly, Assel Smaiyl
46. ["Give a Positive Review Only": An Early Investigation Into In-Paper Prompt Injection Attacks and Defenses for AI Reviewers](http://arxiv.org/abs/2511.01287v1) — arXiv:2511.01287 — 2025-11-03 — cs.CL — Qin Zhou, Zhexin Zhang, Zhi Li, Limin Sun
47. [DRIP: Defending Prompt Injection via Token-wise Representation Editing and Residual Instruction Fusion](http://arxiv.org/abs/2511.00447v2) — arXiv:2511.00447 — 2025-11-01 — cs.CR — Ruofan Liu, Yun Lin, Zhiyong Huang, Jin Song Dong
48. [Reasoning Up the Instruction Ladder for Controllable Language Models](http://arxiv.org/abs/2511.04694v3) — arXiv:2511.04694 — 2025-10-30 — cs.CL — Zishuo Zheng, Vidhisha Balachandran, Chan Young Park, Faeze Brahman, Sachin Kumar
49. [Agent Skills Enable a New Class of Realistic and Trivially Simple Prompt Injections](http://arxiv.org/abs/2510.26328v1) — arXiv:2510.26328 — 2025-10-30 — cs.LG — David Schmotz, Sahar Abdelnabi, Maksym Andriushchenko
50. [Fortytwo: Swarm Inference with Peer-Ranked Consensus](http://arxiv.org/abs/2510.24801v1) — arXiv:2510.24801 — 2025-10-27 — cs.LG — Vladyslav Larin, Ihor Naumenko, Aleksei Ivashov, Ivan Nikitin, Alexander Firsov
51. [QueryIPI: Query-agnostic Indirect Prompt Injection on Coding Agents](http://arxiv.org/abs/2510.23675v1) — arXiv:2510.23675 — 2025-10-27 — cs.CR — Yuchong Xie, Zesen Liu, Mingyu Luo, Zhixiang Zhang, Kaikai Zhang, et al.
52. [Sentra-Guard: A Multilingual Human-AI Framework for Real-Time Defense Against Adversarial LLM Jailbreaks](http://arxiv.org/abs/2510.22628v1) — arXiv:2510.22628 — 2025-10-26 — cs.CR — Md. Mehedi Hasan, Ziaur Rahman, Rafid Mostafiz, Md. Abir Hossain
53. [Soft Instruction De-escalation Defense](http://arxiv.org/abs/2510.21057v1) — arXiv:2510.21057 — 2025-10-24 — cs.CR — Nils Philipp Walter, Chawin Sitawarin, Jamie Hayes, David Stutz, Ilia Shumailov
54. [Defending Against Prompt Injection with DataFilter](http://arxiv.org/abs/2510.19207v1) — arXiv:2510.19207 — 2025-10-22 — cs.CR — Yizhu Wang, Sizhe Chen, Raghad Alkhudair, Basel Alomair, David Wagner
55. [OpenGuardrails: A Configurable, Unified, and Scalable Guardrails Platform for Large Language Models](http://arxiv.org/abs/2510.19169v2) — arXiv:2510.19169 — 2025-10-22 — cs.CR — Thomas Wang, Haowen Li
56. [CourtGuard: A Local, Multiagent Prompt Injection Classifier](http://arxiv.org/abs/2510.19844v1) — arXiv:2510.19844 — 2025-10-20 — cs.CR — Isaac Wu, Michael Maslowski
57. [Black-box Optimization of LLM Outputs by Asking for Directions](http://arxiv.org/abs/2510.16794v1) — arXiv:2510.16794 — 2025-10-19 — cs.CR — Jie Zhang, Meng Ding, Yang Liu, Jue Hong, Florian Tramèr
58. [ATA: A Neuro-Symbolic Approach to Implement Autonomous and Trustworthy Agents](http://arxiv.org/abs/2510.16381v1) — arXiv:2510.16381 — 2025-10-18 — cs.CL — David Peer, Sebastian Stabinger
59. [Prompt injections as a tool for preserving identity in GAI image descriptions](http://arxiv.org/abs/2510.16128v1) — arXiv:2510.16128 — 2025-10-17 — cs.CR — Kate Glazko, Jennifer Mankoff
60. [PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features](http://arxiv.org/abs/2510.14005v2) — arXiv:2510.14005 — 2025-10-15 — cs.CR — Wei Zou, Yupei Liu, Yanting Wang, Ying Chen, Neil Gong, et al.
61. [In-Browser LLM-Guided Fuzzing for Real-Time Prompt Injection Testing in Agentic AI Browsers](http://arxiv.org/abs/2510.13543v1) — arXiv:2510.13543 — 2025-10-15 — cs.CR — Avihay Cohen
62. [Protect: Towards Robust Guardrailing Stack for Trustworthy Enterprise LLM Systems](http://arxiv.org/abs/2510.13351v1) — arXiv:2510.13351 — 2025-10-15 — cs.CL — Karthik Avinash, Nikhil Pareek, Rishav Hada
63. [PromptLocate: Localizing Prompt Injection Attacks](http://arxiv.org/abs/2510.12252v2) — arXiv:2510.12252 — 2025-10-14 — cs.CR — Yuqi Jia, Yupei Liu, Zedian Shao, Jinyuan Jia, Neil Gong
64. [MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents](http://arxiv.org/abs/2510.15994v1) — arXiv:2510.15994 — 2025-10-14 — cs.CR — Dongsen Zhang, Zekun Li, Xu Luo, Xuannan Liu, Peipei Li, et al.
65. [Countermind: A Multi-Layered Security Architecture for Large Language Models](http://arxiv.org/abs/2510.11837v1) — arXiv:2510.11837 — 2025-10-13 — cs.CR — Dominik Schwarz
66. [Attacks by Content: Automated Fact-checking is an AI Security Issue](http://arxiv.org/abs/2510.11238v1) — arXiv:2510.11238 — 2025-10-13 — cs.CL — Michael Schlichtkrull
67. [Text Prompt Injection of Vision Language Models](http://arxiv.org/abs/2510.09849v1) — arXiv:2510.09849 — 2025-10-10 — cs.CL — Ruizhe Zhu
68. [Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols](http://arxiv.org/abs/2510.09462v1) — arXiv:2510.09462 — 2025-10-10 — cs.LG — Mikhail Terekhov, Alexander Panfilov, Daniil Dzenhaliou, Caglar Gulcehre, Maksym Andriushchenko, et al.
69. [Exploiting Web Search Tools of AI Agents for Data Exfiltration](http://arxiv.org/abs/2510.09093v1) — arXiv:2510.09093 — 2025-10-10 — cs.CR — Dennis Rall, Bernhard Bauer, Mohit Mittal, Thomas Fraunholz
70. [The Attacker Moves Second: Stronger Adaptive Attacks Bypass Defenses Against Llm Jailbreaks and Prompt Injections](http://arxiv.org/abs/2510.09023v1) — arXiv:2510.09023 — 2025-10-10 — cs.LG — Milad Nasr, Nicholas Carlini, Chawin Sitawarin, Sander V. Schulhoff, Jamie Hayes, et al.
71. ["I know it's not right, but that's what it said to do": Investigating Trust in AI Chatbots for Cybersecurity Policy](http://arxiv.org/abs/2510.08917v1) — arXiv:2510.08917 — 2025-10-10 — cs.HC — Brandon Lit, Edward Crowder, Daniel Vogel, Hassan Khan
72. [CommandSans: Securing AI Agents with Surgical Precision Prompt Sanitization](http://arxiv.org/abs/2510.08829v1) — arXiv:2510.08829 — 2025-10-09 — cs.CR — Debeshee Das, Luca Beurer-Kellner, Marc Fischer, Maximilian Baader
73. [Practical and Stealthy Touch-Guided Jailbreak Attacks on Deployed Mobile Vision-Language Agents](http://arxiv.org/abs/2510.07809v2) — arXiv:2510.07809 — 2025-10-09 — cs.CR — Renhua Ding, Xiao Yang, Zhengwei Fang, Jun Luo, Kun He, et al.
74. [Towards Reliable and Practical LLM Security Evaluations via Bayesian Modelling](http://arxiv.org/abs/2510.05709v1) — arXiv:2510.05709 — 2025-10-07 — cs.CR — Mary Llewellyn, Annie Gray, Josh Collyer, Michael Harries
75. [Adversarial Reinforcement Learning for Large Language Model Agent Safety](http://arxiv.org/abs/2510.05442v1) — arXiv:2510.05442 — 2025-10-06 — cs.LG — Zizhao Wang, Dingcheng Li, Vaishakh Keshava, Phillip Wallis, Ananth Balashankar, et al.
76. [Indirect Prompt Injections: Are Firewalls All You Need, or Stronger Benchmarks?](http://arxiv.org/abs/2510.05244v1) — arXiv:2510.05244 — 2025-10-06 — cs.CR — Rishika Bhagwatkar, Kevin Kasa, Abhay Puri, Gabriel Huang, Irina Rish, et al.
77. [Imperceptible Jailbreaking against Large Language Models](http://arxiv.org/abs/2510.05025v1) — arXiv:2510.05025 — 2025-10-06 — cs.CL — Kuofeng Gao, Yiming Li, Chao Du, Xin Wang, Xingjun Ma, et al.
78. [RL Is a Hammer and LLMs Are Nails: A Simple Reinforcement Learning Recipe for Strong Prompt Injection](http://arxiv.org/abs/2510.04885v1) — arXiv:2510.04885 — 2025-10-06 — cs.CR — Yuxin Wen, Arman Zharmagambetov, Ivan Evtimov, Narine Kokhlikyan, Tom Goldstein, et al.
79. [Unified Threat Detection and Mitigation Framework (UTDMF): Combating Prompt Injection, Deception, and Bias in Enterprise-Scale Transformers](http://arxiv.org/abs/2510.04528v1) — arXiv:2510.04528 — 2025-10-06 — cs.CR — Santhosh KumarRavindran
80. [VortexPIA: Indirect Prompt Injection Attack against LLMs for Efficient Extraction of User Privacy](http://arxiv.org/abs/2510.04261v1) — arXiv:2510.04261 — 2025-10-05 — cs.CR — Yu Cui, Sicheng Pan, Yifei Liu, Haibin Zhang, Cong Zuo
81. [AgentTypo: Adaptive Typographic Prompt Injection Attacks against Black-box Multimodal Agents](http://arxiv.org/abs/2510.04257v1) — arXiv:2510.04257 — 2025-10-05 — cs.CR — Yanjie Li, Yiming Cao, Dong Wang, Bin Xiao
82. [Backdoor-Powered Prompt Injection Attacks Nullify Defense Methods](http://arxiv.org/abs/2510.03705v1) — arXiv:2510.03705 — 2025-10-04 — cs.CR — Yulin Chen, Haoran Li, Yuan Sui, Yangqiu Song, Bryan Hooi
83. [FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents](http://arxiv.org/abs/2510.03204v1) — arXiv:2510.03204 — 2025-10-03 — cs.CL — Imene Kerboua, Sahar Omidi Shayegan, Megh Thakkar, Xing Han Lù, Léo Boisvert, et al.
84. [AdvEvo-MARL: Shaping Internalized Safety through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2510.01586v1) — arXiv:2510.01586 — 2025-10-02 — cs.AI — Zhenyu Pan, Yiting Zhang, Zhuo Liu, Yolo Yunlong Tang, Zeliang Zhang, et al.
85. [WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents](http://arxiv.org/abs/2510.01354v1) — arXiv:2510.01354 — 2025-10-01 — cs.CR — Yinuo Liu, Ruohan Xu, Xilong Wang, Yuqi Jia, Neil Zhenqiang Gong
86. [A Call to Action for a Secure-by-Design Generative AI Paradigm](http://arxiv.org/abs/2510.00451v1) — arXiv:2510.00451 — 2025-10-01 — cs.CR — Dalal Alharthi, Ivan Roberto Kawaminami Garcia
87. [Fairness Testing in Retrieval-Augmented Generation: How Small Perturbations Reveal Bias in Small Language Models](http://arxiv.org/abs/2509.26584v1) — arXiv:2509.26584 — 2025-09-30 — cs.AI — Matheus Vinicius da Silva de Oliveira, Jonathan de Andrade Silva, Awdren de Lima Fontao
88. [Better Privilege Separation for Agents by Restricting Data Types](http://arxiv.org/abs/2509.25926v1) — arXiv:2509.25926 — 2025-09-30 — cs.CR — Dennis Jacob, Emad Alghamdi, Zhanhao Hu, Basel Alomair, David Wagner
89. [How Diffusion Models Memorize](http://arxiv.org/abs/2509.25705v1) — arXiv:2509.25705 — 2025-09-30 — cs.CV — Juyeop Kim, Songkuk Kim, Jong-Seok Lee
90. [Fingerprinting LLMs via Prompt Injection](http://arxiv.org/abs/2509.25448v2) — arXiv:2509.25448 — 2025-09-29 — cs.CR — Yuepeng Hu, Zhengyuan Jiang, Mengyuan Li, Osama Ahmed, Zhicong Huang, et al.
91. [SecInfer: Preventing Prompt Injection via Inference-time Scaling](http://arxiv.org/abs/2509.24967v4) — arXiv:2509.24967 — 2025-09-29 — cs.CR — Yupei Liu, Yanting Wang, Yuqi Jia, Jinyuan Jia, Neil Zhenqiang Gong
92. [Policy-as-Prompt: Turning AI Governance Rules into Guardrails for AI Agents](http://arxiv.org/abs/2509.23994v2) — arXiv:2509.23994 — 2025-09-28 — cs.CL — Gauri Kholkar, Ratinder Ahuja
93. [SafeSearch: Automated Red-Teaming for the Safety of LLM-Based Search Agents](http://arxiv.org/abs/2509.23694v3) — arXiv:2509.23694 — 2025-09-28 — cs.AI — Jianshuo Dong, Sheng Guo, Hao Wang, Xun Chen, Zhuotao Liu, et al.
94. [ReliabilityRAG: Effective and Provably Robust Defense for RAG-based Web-Search](http://arxiv.org/abs/2509.23519v1) — arXiv:2509.23519 — 2025-09-27 — cs.CR — Zeyu Shen, Basileal Imana, Tong Wu, Chong Xiang, Prateek Mittal, et al.
95. [ChatInject: Abusing Chat Templates for Prompt Injection in LLM Agents](http://arxiv.org/abs/2509.22830v1) — arXiv:2509.22830 — 2025-09-26 — cs.CL — Hwan Chang, Yonghyun Jun, Hwanhee Lee
96. ["Your AI, My Shell": Demystifying Prompt Injection Attacks on Agentic AI Coding Editors](http://arxiv.org/abs/2509.22040v1) — arXiv:2509.22040 — 2025-09-26 — cs.CR — Yue Liu, Yanjie Zhao, Yunbo Lyu, Ting Zhang, Haoyu Wang, et al.
97. [Rule Encoding and Compliance in Large Language Models: An Information-Theoretic Analysis](http://arxiv.org/abs/2510.05106v2) — arXiv:2510.05106 — 2025-09-23 — cs.AI — Joachim Diederich
98. [LLMZ+: Contextual Prompt Whitelist Principles for Agentic LLMs](http://arxiv.org/abs/2509.18557v1) — arXiv:2509.18557 — 2025-09-23 — cs.AI — Tom Pawelek, Raj Patel, Charlotte Crowell, Noorbakhsh Amiri, Sudip Mittal, et al.
99. [D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models](http://arxiv.org/abs/2509.17938v1) — arXiv:2509.17938 — 2025-09-22 — cs.CL — Satyapriya Krishna, Andy Zou, Rahul Gupta, Eliot Krzysztof Jones, Nick Winter, et al.
100. [Design and Implementation of a Secure RAG-Enhanced AI Chatbot for Smart Tourism Customer Service: Defending Against Prompt Injection Attacks -- A Case Study of Hsinchu, Taiwan](http://arxiv.org/abs/2509.21367v1) — arXiv:2509.21367 — 2025-09-22 — cs.CR — Yu-Kai Shih, You-Kai Kang
101. [SilentStriker:Toward Stealthy Bit-Flip Attacks on Large Language Models](http://arxiv.org/abs/2509.17371v2) — arXiv:2509.17371 — 2025-09-22 — cs.CR — Haotian Xu, Qingsong Peng, Jie Shi, Huadi Zheng, Yu Li, et al.
102. [EmoQ: Speech Emotion Recognition via Speech-Aware Q-Former and Large Language Model](http://arxiv.org/abs/2509.15775v1) — arXiv:2509.15775 — 2025-09-19 — cs.SD — Yiqing Yang, Man-Wai Mak
103. [Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems](http://arxiv.org/abs/2509.14956v1) — arXiv:2509.14956 — 2025-09-18 — cs.AI — Diego Gosmar, Deborah A. Dahl
104. [Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents](http://arxiv.org/abs/2509.13597v1) — arXiv:2509.13597 — 2025-09-16 — cs.CR — Abhishek Goswami
105. [A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks](http://arxiv.org/abs/2509.14285v4) — arXiv:2509.14285 — 2025-09-16 — cs.CR — S M Asif Hossain, Ruksat Khan Shayoni, Mohd Ruhul Ameen, Akif Islam, M. F. Mridha, et al.
106. [Early Approaches to Adversarial Fine-Tuning for Prompt Injection Defense: A 2022 Study of GPT-3 and Contemporary Models](http://arxiv.org/abs/2509.14271v1) — arXiv:2509.14271 — 2025-09-15 — cs.CR — Gustavo Sandoval, Denys Fenchenko, Junyao Chen
107. [Securing AI Agents: Implementing Role-Based Access Control for Industrial Applications](http://arxiv.org/abs/2509.11431v1) — arXiv:2509.11431 — 2025-09-14 — cs.AI — Aadil Gani Ganie
108. [Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](http://arxiv.org/abs/2509.10248v3) — arXiv:2509.10248 — 2025-09-12 — cs.LG — Janis Keuper
109. [Realism Control One-step Diffusion for Real-World Image Super-Resolution](http://arxiv.org/abs/2509.10122v2) — arXiv:2509.10122 — 2025-09-12 — cs.CV — Zongliang Wu, Siming Zheng, Peng-Tao Jiang, Xin Yuan
110. [When Your Reviewer is an LLM: Biases, Divergence, and Prompt Injection Risks in Peer Review](http://arxiv.org/abs/2509.09912v1) — arXiv:2509.09912 — 2025-09-12 — cs.CY — Changjia Zhu, Junjie Xiong, Renkai Ma, Zhicong Lu, Yao Liu, et al.
111. [Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations](http://arxiv.org/abs/2509.08646v1) — arXiv:2509.08646 — 2025-09-10 — cs.CR — Ron F. Del Rosario, Klaudia Krawiecka, Christian Schroeder de Witt
